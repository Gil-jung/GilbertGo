{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlgo.data.parallel_processor import GoDataProcessor\n",
    "from dlgo.encoders.oneplane import OnePlaneEncoder\n",
    "from dlgo.networks.small import Small\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_board_rows, go_board_cols = 19, 19\n",
    "num_classes = go_board_rows * go_board_cols\n",
    "num_games = 100\n",
    "\n",
    "def compute_acc(argmax, y):\n",
    "    count = 0\n",
    "    for i in range(len(argmax)):\n",
    "        if argmax[i] == y[i]:\n",
    "            count += 1\n",
    "    return count / len(argmax)\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data,nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Reading cached index page\n",
      "KGS-2019_04-19-1255-.tar.gz 1255\n",
      "KGS-2019_03-19-1478-.tar.gz 1478\n",
      "KGS-2019_02-19-1412-.tar.gz 1412\n",
      "KGS-2019_01-19-2095-.tar.gz 2095\n",
      "KGS-2018_12-19-1992-.tar.gz 1992\n",
      "KGS-2018_11-19-1879-.tar.gz 1879\n",
      "KGS-2018_10-19-1209-.tar.gz 1209\n",
      "KGS-2018_09-19-1587-.tar.gz 1587\n",
      "KGS-2018_08-19-1447-.tar.gz 1447\n",
      "KGS-2018_07-19-949-.tar.gz 949\n",
      "KGS-2018_06-19-1002-.tar.gz 1002\n",
      "KGS-2018_05-19-1590-.tar.gz 1590\n",
      "KGS-2018_04-19-1612-.tar.gz 1612\n",
      "KGS-2018_03-19-833-.tar.gz 833\n",
      "KGS-2018_02-19-1167-.tar.gz 1167\n",
      "KGS-2018_01-19-1526-.tar.gz 1526\n",
      "KGS-2017_12-19-1488-.tar.gz 1488\n",
      "KGS-2017_11-19-945-.tar.gz 945\n",
      "KGS-2017_10-19-1351-.tar.gz 1351\n",
      "KGS-2017_09-19-1353-.tar.gz 1353\n",
      "KGS-2017_08-19-2205-.tar.gz 2205\n",
      "KGS-2017_07-19-1191-.tar.gz 1191\n",
      "KGS-2017_06-19-910-.tar.gz 910\n",
      "KGS-2017_05-19-847-.tar.gz 847\n",
      "KGS-2017_04-19-913-.tar.gz 913\n",
      "KGS-2017_03-19-717-.tar.gz 717\n",
      "KGS-2017_02-19-525-.tar.gz 525\n",
      "KGS-2017_01-19-733-.tar.gz 733\n",
      "KGS-2016_12-19-1208-.tar.gz 1208\n",
      "KGS-2016_11-19-980-.tar.gz 980\n",
      "KGS-2016_10-19-925-.tar.gz 925\n",
      "KGS-2016_09-19-1170-.tar.gz 1170\n",
      "KGS-2016_08-19-1374-.tar.gz 1374\n",
      "KGS-2016_07-19-1432-.tar.gz 1432\n",
      "KGS-2016_06-19-1540-.tar.gz 1540\n",
      "KGS-2016_05-19-1011-.tar.gz 1011\n",
      "KGS-2016_04-19-1081-.tar.gz 1081\n",
      "KGS-2016_03-19-895-.tar.gz 895\n",
      "KGS-2016_02-19-577-.tar.gz 577\n",
      "KGS-2016_01-19-756-.tar.gz 756\n",
      "KGS-2015-19-8133-.tar.gz 8133\n",
      "KGS-2014-19-13029-.tar.gz 13029\n",
      "KGS-2013-19-13783-.tar.gz 13783\n",
      "KGS-2012-19-13665-.tar.gz 13665\n",
      "KGS-2011-19-19099-.tar.gz 19099\n",
      "KGS-2010-19-17536-.tar.gz 17536\n",
      "KGS-2009-19-18837-.tar.gz 18837\n",
      "KGS-2008-19-14002-.tar.gz 14002\n",
      "KGS-2007-19-11644-.tar.gz 11644\n",
      "KGS-2006-19-10388-.tar.gz 10388\n",
      "KGS-2005-19-13941-.tar.gz 13941\n",
      "KGS-2004-19-12106-.tar.gz 12106\n",
      "KGS-2003-19-7582-.tar.gz 7582\n",
      "KGS-2002-19-3646-.tar.gz 3646\n",
      "KGS-2001-19-2298-.tar.gz 2298\n",
      ">>> Reading cached index page\n",
      "KGS-2019_04-19-1255-.tar.gz 1255\n",
      "KGS-2019_03-19-1478-.tar.gz 1478\n",
      "KGS-2019_02-19-1412-.tar.gz 1412\n",
      "KGS-2019_01-19-2095-.tar.gz 2095\n",
      "KGS-2018_12-19-1992-.tar.gz 1992\n",
      "KGS-2018_11-19-1879-.tar.gz 1879\n",
      "KGS-2018_10-19-1209-.tar.gz 1209\n",
      "KGS-2018_09-19-1587-.tar.gz 1587\n",
      "KGS-2018_08-19-1447-.tar.gz 1447\n",
      "KGS-2018_07-19-949-.tar.gz 949\n",
      "KGS-2018_06-19-1002-.tar.gz 1002\n",
      "KGS-2018_05-19-1590-.tar.gz 1590\n",
      "KGS-2018_04-19-1612-.tar.gz 1612\n",
      "KGS-2018_03-19-833-.tar.gz 833\n",
      "KGS-2018_02-19-1167-.tar.gz 1167\n",
      "KGS-2018_01-19-1526-.tar.gz 1526\n",
      "KGS-2017_12-19-1488-.tar.gz 1488\n",
      "KGS-2017_11-19-945-.tar.gz 945\n",
      "KGS-2017_10-19-1351-.tar.gz 1351\n",
      "KGS-2017_09-19-1353-.tar.gz 1353\n",
      "KGS-2017_08-19-2205-.tar.gz 2205\n",
      "KGS-2017_07-19-1191-.tar.gz 1191\n",
      "KGS-2017_06-19-910-.tar.gz 910\n",
      "KGS-2017_05-19-847-.tar.gz 847\n",
      "KGS-2017_04-19-913-.tar.gz 913\n",
      "KGS-2017_03-19-717-.tar.gz 717\n",
      "KGS-2017_02-19-525-.tar.gz 525\n",
      "KGS-2017_01-19-733-.tar.gz 733\n",
      "KGS-2016_12-19-1208-.tar.gz 1208\n",
      "KGS-2016_11-19-980-.tar.gz 980\n",
      "KGS-2016_10-19-925-.tar.gz 925\n",
      "KGS-2016_09-19-1170-.tar.gz 1170\n",
      "KGS-2016_08-19-1374-.tar.gz 1374\n",
      "KGS-2016_07-19-1432-.tar.gz 1432\n",
      "KGS-2016_06-19-1540-.tar.gz 1540\n",
      "KGS-2016_05-19-1011-.tar.gz 1011\n",
      "KGS-2016_04-19-1081-.tar.gz 1081\n",
      "KGS-2016_03-19-895-.tar.gz 895\n",
      "KGS-2016_02-19-577-.tar.gz 577\n",
      "KGS-2016_01-19-756-.tar.gz 756\n",
      "KGS-2015-19-8133-.tar.gz 8133\n",
      "KGS-2014-19-13029-.tar.gz 13029\n",
      "KGS-2013-19-13783-.tar.gz 13783\n",
      "KGS-2012-19-13665-.tar.gz 13665\n",
      "KGS-2011-19-19099-.tar.gz 19099\n",
      "KGS-2010-19-17536-.tar.gz 17536\n",
      "KGS-2009-19-18837-.tar.gz 18837\n",
      "KGS-2008-19-14002-.tar.gz 14002\n",
      "KGS-2007-19-11644-.tar.gz 11644\n",
      "KGS-2006-19-10388-.tar.gz 10388\n",
      "KGS-2005-19-13941-.tar.gz 13941\n",
      "KGS-2004-19-12106-.tar.gz 12106\n",
      "KGS-2003-19-7582-.tar.gz 7582\n",
      "KGS-2002-19-3646-.tar.gz 3646\n",
      "KGS-2001-19-2298-.tar.gz 2298\n",
      "total num games: 179689\n",
      "Drawn 100 samples:\n",
      ">>> Reading cached index page\n",
      "KGS-2019_04-19-1255-.tar.gz 1255\n",
      "KGS-2019_03-19-1478-.tar.gz 1478\n",
      "KGS-2019_02-19-1412-.tar.gz 1412\n",
      "KGS-2019_01-19-2095-.tar.gz 2095\n",
      "KGS-2018_12-19-1992-.tar.gz 1992\n",
      "KGS-2018_11-19-1879-.tar.gz 1879\n",
      "KGS-2018_10-19-1209-.tar.gz 1209\n",
      "KGS-2018_09-19-1587-.tar.gz 1587\n",
      "KGS-2018_08-19-1447-.tar.gz 1447\n",
      "KGS-2018_07-19-949-.tar.gz 949\n",
      "KGS-2018_06-19-1002-.tar.gz 1002\n",
      "KGS-2018_05-19-1590-.tar.gz 1590\n",
      "KGS-2018_04-19-1612-.tar.gz 1612\n",
      "KGS-2018_03-19-833-.tar.gz 833\n",
      "KGS-2018_02-19-1167-.tar.gz 1167\n",
      "KGS-2018_01-19-1526-.tar.gz 1526\n",
      "KGS-2017_12-19-1488-.tar.gz 1488\n",
      "KGS-2017_11-19-945-.tar.gz 945\n",
      "KGS-2017_10-19-1351-.tar.gz 1351\n",
      "KGS-2017_09-19-1353-.tar.gz 1353\n",
      "KGS-2017_08-19-2205-.tar.gz 2205\n",
      "KGS-2017_07-19-1191-.tar.gz 1191\n",
      "KGS-2017_06-19-910-.tar.gz 910\n",
      "KGS-2017_05-19-847-.tar.gz 847\n",
      "KGS-2017_04-19-913-.tar.gz 913\n",
      "KGS-2017_03-19-717-.tar.gz 717\n",
      "KGS-2017_02-19-525-.tar.gz 525\n",
      "KGS-2017_01-19-733-.tar.gz 733\n",
      "KGS-2016_12-19-1208-.tar.gz 1208\n",
      "KGS-2016_11-19-980-.tar.gz 980\n",
      "KGS-2016_10-19-925-.tar.gz 925\n",
      "KGS-2016_09-19-1170-.tar.gz 1170\n",
      "KGS-2016_08-19-1374-.tar.gz 1374\n",
      "KGS-2016_07-19-1432-.tar.gz 1432\n",
      "KGS-2016_06-19-1540-.tar.gz 1540\n",
      "KGS-2016_05-19-1011-.tar.gz 1011\n",
      "KGS-2016_04-19-1081-.tar.gz 1081\n",
      "KGS-2016_03-19-895-.tar.gz 895\n",
      "KGS-2016_02-19-577-.tar.gz 577\n",
      "KGS-2016_01-19-756-.tar.gz 756\n",
      "KGS-2015-19-8133-.tar.gz 8133\n",
      "KGS-2014-19-13029-.tar.gz 13029\n",
      "KGS-2013-19-13783-.tar.gz 13783\n",
      "KGS-2012-19-13665-.tar.gz 13665\n",
      "KGS-2011-19-19099-.tar.gz 19099\n",
      "KGS-2010-19-17536-.tar.gz 17536\n",
      "KGS-2009-19-18837-.tar.gz 18837\n",
      "KGS-2008-19-14002-.tar.gz 14002\n",
      "KGS-2007-19-11644-.tar.gz 11644\n",
      "KGS-2006-19-10388-.tar.gz 10388\n",
      "KGS-2005-19-13941-.tar.gz 13941\n",
      "KGS-2004-19-12106-.tar.gz 12106\n",
      "KGS-2003-19-7582-.tar.gz 7582\n",
      "KGS-2002-19-3646-.tar.gz 3646\n",
      "KGS-2001-19-2298-.tar.gz 2298\n",
      "11264\n"
     ]
    }
   ],
   "source": [
    "encoder = OnePlaneEncoder((go_board_rows, go_board_cols))  # First we create an encoder of board size.\n",
    "\n",
    "processor = GoDataProcessor(encoder=encoder.name())  # Then we initialize a Go Data processor with it.\n",
    "\n",
    "generator = processor.load_go_data('train', num_games, use_generator=True)  # From the processor we create two data generators, for training and testing.\n",
    "test_generator = processor.load_go_data('test', num_games, use_generator=True)\n",
    "\n",
    "model = Small(go_board_rows, encoder.num_planes).cuda()\n",
    "\n",
    "optimizer = SGD(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "total_steps = generator.get_num_samples() // BATCH_SIZE\n",
    "print(generator.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Small(\n",
       "  (conv1): Conv2d(1, 48, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "  (conv2): Conv2d(48, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv4): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=11552, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=361, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0309, 0.9091, 0.0691,  ..., 0.9886, 0.0867, 0.8542],\n",
       "          [0.8647, 0.5342, 0.7568,  ..., 0.4739, 0.2088, 0.1639],\n",
       "          [0.3123, 0.4012, 0.8679,  ..., 0.6941, 0.2763, 0.1505],\n",
       "          ...,\n",
       "          [0.0465, 0.8297, 0.8725,  ..., 0.7844, 0.0643, 0.9094],\n",
       "          [0.0106, 0.7013, 0.5412,  ..., 0.8544, 0.6170, 0.4582],\n",
       "          [0.3127, 0.6905, 0.2242,  ..., 0.0474, 0.8159, 0.5017]]],\n",
       "\n",
       "\n",
       "        [[[0.6942, 0.2762, 0.6338,  ..., 0.1202, 0.2771, 0.5740],\n",
       "          [0.8529, 0.3737, 0.4984,  ..., 0.8490, 0.6774, 0.7114],\n",
       "          [0.9966, 0.3081, 0.1232,  ..., 0.1555, 0.7079, 0.4874],\n",
       "          ...,\n",
       "          [0.9467, 0.3802, 0.9262,  ..., 0.6556, 0.5944, 0.9155],\n",
       "          [0.7490, 0.7303, 0.2930,  ..., 0.9914, 0.9121, 0.2489],\n",
       "          [0.5065, 0.2035, 0.6502,  ..., 0.1183, 0.6967, 0.1514]]],\n",
       "\n",
       "\n",
       "        [[[0.6305, 0.2060, 0.6713,  ..., 0.3798, 0.9796, 0.7821],\n",
       "          [0.5201, 0.4192, 0.7338,  ..., 0.9780, 0.1205, 0.4547],\n",
       "          [0.8291, 0.8268, 0.1669,  ..., 0.3271, 0.7086, 0.6467],\n",
       "          ...,\n",
       "          [0.0156, 0.6228, 0.3672,  ..., 0.5561, 0.7341, 0.5231],\n",
       "          [0.1279, 0.8005, 0.5463,  ..., 0.3368, 0.1929, 0.9540],\n",
       "          [0.7063, 0.2839, 0.6315,  ..., 0.3701, 0.5601, 0.3506]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.5090, 0.2640, 0.1441,  ..., 0.0511, 0.0855, 0.1110],\n",
       "          [0.0551, 0.3110, 0.5044,  ..., 0.9798, 0.8585, 0.2591],\n",
       "          [0.8554, 0.7159, 0.9420,  ..., 0.4831, 0.0228, 0.7653],\n",
       "          ...,\n",
       "          [0.7475, 0.1602, 0.8241,  ..., 0.6994, 0.6710, 0.7937],\n",
       "          [0.0449, 0.4450, 0.1219,  ..., 0.7923, 0.7068, 0.8942],\n",
       "          [0.9829, 0.0254, 0.4002,  ..., 0.7343, 0.0099, 0.5040]]],\n",
       "\n",
       "\n",
       "        [[[0.7983, 0.1157, 0.0593,  ..., 0.4130, 0.1646, 0.0945],\n",
       "          [0.8514, 0.3598, 0.0230,  ..., 0.4567, 0.6211, 0.0393],\n",
       "          [0.9514, 0.4197, 0.7144,  ..., 0.7253, 0.1393, 0.9979],\n",
       "          ...,\n",
       "          [0.6882, 0.0917, 0.4774,  ..., 0.1643, 0.2651, 0.4576],\n",
       "          [0.7728, 0.8423, 0.9717,  ..., 0.5940, 0.6749, 0.0367],\n",
       "          [0.6364, 0.2237, 0.4993,  ..., 0.5296, 0.0385, 0.0528]]],\n",
       "\n",
       "\n",
       "        [[[0.6102, 0.0886, 0.0433,  ..., 0.6610, 0.7669, 0.0076],\n",
       "          [0.0965, 0.6514, 0.4979,  ..., 0.6937, 0.4266, 0.8485],\n",
       "          [0.8398, 0.6198, 0.8815,  ..., 0.6924, 0.1195, 0.3318],\n",
       "          ...,\n",
       "          [0.1160, 0.9614, 0.5255,  ..., 0.5622, 0.1175, 0.3355],\n",
       "          [0.4211, 0.4049, 0.6284,  ..., 0.4898, 0.3828, 0.6200],\n",
       "          [0.0542, 0.2307, 0.9546,  ..., 0.4279, 0.6507, 0.5678]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = torch.Tensor(np.random.rand(32, 1, 19, 19))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\삼성\\AppData\\Local\\Temp\\ipykernel_19632\\2049571338.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 19,  63, 332, 347,  38, 167, 228, 189, 154,  71, 314, 301, 213, 125,\n",
       "        151, 197,  54, 300, 250, 338,  66,  20, 336, 321,  22, 195,  48, 299,\n",
       "        215, 246, 165, 114])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.Tensor(np.random.randint(0, 362, size=(32)))\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 19, 19])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "tot_loss = 0.0\n",
    "steps = 0\n",
    "\n",
    "for x, y in generator.generate(BATCH_SIZE, num_classes):\n",
    "    steps += 1\n",
    "    optimizer.zero_grad()\n",
    "    x = x.cuda()\n",
    "    y_ = model(x)\n",
    "    loss = loss_fn(y_, y.cuda()) \n",
    "    loss.backward()\n",
    "    tot_loss += loss.item()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps >= total_steps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0020, 0.0029, 0.0036,  ..., 0.0015, 0.0033, 0.0029],\n",
       "        [0.0014, 0.0025, 0.0023,  ..., 0.0018, 0.0030, 0.0021],\n",
       "        [0.0021, 0.0029, 0.0036,  ..., 0.0016, 0.0032, 0.0030],\n",
       "        ...,\n",
       "        [0.0026, 0.0029, 0.0025,  ..., 0.0023, 0.0041, 0.0024],\n",
       "        [0.0021, 0.0034, 0.0031,  ..., 0.0023, 0.0031, 0.0023],\n",
       "        [0.0026, 0.0029, 0.0026,  ..., 0.0025, 0.0041, 0.0025]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 361])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "tot_loss = 0.0\n",
    "steps = 0\n",
    "\n",
    "x, y = next(iter(generator.generate(BATCH_SIZE, num_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 73,  71,  50, 288, 249, 211, 290, 268, 250, 270, 267, 286, 269, 289,\n",
       "        287, 306, 232, 154,  43,  65,  40,  59,  41,  61,  42,  62,  63,  82,\n",
       "         83,  64,  44, 101,  52, 309, 193, 192, 156, 136, 102,  85, 121, 138,\n",
       "        123,  87,  67,  86, 125,  69,  51, 127, 165, 145, 107,  70, 108, 109,\n",
       "        128, 126, 106,  72,  53, 110, 147, 163,  92, 141, 162, 182, 104, 149,\n",
       "        168, 150, 111, 129, 186, 203, 224, 180, 119, 137,  81, 100,  99,  80,\n",
       "        120,  81,  98,  77,  96,  39,  20,  19,   1,  97, 116,  78, 115, 117,\n",
       "        118,  76,  57,  21,  22, 134, 158, 139, 140, 159, 160, 178, 179, 198,\n",
       "        161, 199, 144, 164, 142, 263, 317, 129, 186,  70,  92, 109, 282, 262,\n",
       "        224, 260])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 19, 19])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in generator.generate(BATCH_SIZE, num_classes):\n",
    "    steps += 1\n",
    "    optimizer.zero_grad()\n",
    "    x = x.cuda()\n",
    "    y_ = model(x)\n",
    "    loss = loss_fn(y_, y.cuda()) \n",
    "    loss.backward()\n",
    "    tot_loss += loss.item()\n",
    "    optimizer.step()\n",
    "\n",
    "    if steps >= total_steps:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0026, 0.0027, 0.0031,  ..., 0.0026, 0.0025, 0.0028],\n",
       "        [0.0025, 0.0027, 0.0030,  ..., 0.0026, 0.0025, 0.0027],\n",
       "        [0.0026, 0.0026, 0.0031,  ..., 0.0026, 0.0025, 0.0028],\n",
       "        ...,\n",
       "        [0.0026, 0.0028, 0.0031,  ..., 0.0025, 0.0025, 0.0029],\n",
       "        [0.0026, 0.0027, 0.0028,  ..., 0.0027, 0.0026, 0.0027],\n",
       "        [0.0027, 0.0027, 0.0031,  ..., 0.0026, 0.0026, 0.0030]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 361])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value, argmax = torch.max(y_, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0035, 0.0035, 0.0035, 0.0034, 0.0035, 0.0034, 0.0035, 0.0034, 0.0036,\n",
       "        0.0034, 0.0037, 0.0034, 0.0037, 0.0035, 0.0038, 0.0037, 0.0039, 0.0036,\n",
       "        0.0037, 0.0036, 0.0037, 0.0035, 0.0039, 0.0036, 0.0038, 0.0037, 0.0037,\n",
       "        0.0038, 0.0040, 0.0037, 0.0041, 0.0040, 0.0040, 0.0038, 0.0043, 0.0038,\n",
       "        0.0042, 0.0037, 0.0043, 0.0039, 0.0042, 0.0039, 0.0044, 0.0039, 0.0043,\n",
       "        0.0039, 0.0043, 0.0041, 0.0043, 0.0040, 0.0044, 0.0042, 0.0043, 0.0046,\n",
       "        0.0045, 0.0044, 0.0046, 0.0043, 0.0047, 0.0046, 0.0047, 0.0045, 0.0048,\n",
       "        0.0047, 0.0053, 0.0047, 0.0050, 0.0049, 0.0051, 0.0047, 0.0050, 0.0048,\n",
       "        0.0051, 0.0049, 0.0051, 0.0051, 0.0049, 0.0050, 0.0049, 0.0050, 0.0048,\n",
       "        0.0055, 0.0048, 0.0055, 0.0052, 0.0054, 0.0053, 0.0050, 0.0052, 0.0048,\n",
       "        0.0051, 0.0046, 0.0051, 0.0048, 0.0053, 0.0051, 0.0056, 0.0052, 0.0052,\n",
       "        0.0052, 0.0055, 0.0052, 0.0055, 0.0053, 0.0052, 0.0055, 0.0053, 0.0054,\n",
       "        0.0054, 0.0056, 0.0053, 0.0054, 0.0054, 0.0056, 0.0057, 0.0063, 0.0061,\n",
       "        0.0035, 0.0035, 0.0034, 0.0035, 0.0035, 0.0035, 0.0035, 0.0036, 0.0034,\n",
       "        0.0034, 0.0034], device='cuda:0', grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 19, 19])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0., -1.,  1.,  0.,  1.,  0.,  1.,  0.,  1., -1., -1.,  1.,\n",
       "          0.,  1.,  1., -1., -1.],\n",
       "        [ 0.,  0., -1.,  0., -1.,  1.,  1.,  0.,  0.,  1.,  0.,  1., -1., -1.,\n",
       "          1.,  0.,  1., -1.,  0.],\n",
       "        [ 0., -1., -1., -1.,  0., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  0., -1.,\n",
       "          1.,  1.,  1.,  1., -1.],\n",
       "        [-1.,  0., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "         -1., -1.,  1.,  1.,  1.],\n",
       "        [-1., -1.,  1., -1.,  1., -1., -1.,  0., -1.,  0., -1., -1.,  1.,  0.,\n",
       "          1., -1., -1., -1., -1.],\n",
       "        [ 1.,  1.,  1., -1.,  1., -1.,  0., -1.,  0., -1.,  1., -1.,  1.,  1.,\n",
       "          0., -1.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  0.,  1.,\n",
       "          1., -1., -1.,  0.,  0.],\n",
       "        [ 1.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0., -1., -1.,  1.,  1.,  1.,\n",
       "         -1.,  0., -1.,  0.,  0.],\n",
       "        [ 1., -1.,  1.,  0.,  0.,  0., -1.,  1., -1., -1., -1., -1.,  1., -1.,\n",
       "         -1.,  0., -1.,  0.,  0.],\n",
       "        [ 1., -1., -1., -1., -1., -1., -1.,  1., -1.,  0., -1.,  1.,  1., -1.,\n",
       "          0.,  0.,  1., -1.,  0.],\n",
       "        [ 1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  0., -1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1., -1., -1.],\n",
       "        [-1.,  1.,  1.,  1., -1., -1., -1., -1.,  0., -1., -1.,  1.,  1.,  0.,\n",
       "         -1.,  1., -1., -1.,  1.],\n",
       "        [-1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1., -1., -1.,  1.,  0.],\n",
       "        [-1.,  1.,  1.,  1.,  0., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,\n",
       "          0., -1.,  1.,  1.,  1.],\n",
       "        [ 1.,  1.,  0.,  1., -1., -1.,  1.,  1.,  0.,  1.,  1.,  1., -1., -1.,\n",
       "         -1., -1., -1.,  1.,  0.],\n",
       "        [ 1.,  0.,  1.,  1., -1.,  0., -1.,  1.,  1., -1., -1., -1.,  0., -1.,\n",
       "          1.,  1.,  1.,  0.,  0.],\n",
       "        [ 0.,  1., -1., -1.,  0.,  0.,  0., -1., -1.,  0.,  0.,  0., -1., -1.,\n",
       "          0.,  0.,  1.,  0.,  0.],\n",
       "        [ 1., -1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         -1., -1.,  1.,  0.,  0.],\n",
       "        [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         -1.,  1.,  1.,  0.,  0.]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
