{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "img should be PIL Image. Got <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, option \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(options):\n\u001b[0;32m     20\u001b[0m     transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     21\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(p\u001b[38;5;241m=\u001b[39moption[\u001b[38;5;241m0\u001b[39m]),\n\u001b[0;32m     22\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mRandomVerticalFlip(p\u001b[38;5;241m=\u001b[39moption[\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m     23\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mRandomRotation(degrees\u001b[38;5;241m=\u001b[39moption[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     24\u001b[0m     ])\n\u001b[1;32m---> 25\u001b[0m     answer[idx] \u001b[38;5;241m=\u001b[39m transform(tensor)\n",
      "File \u001b[1;32mc:\\Users\\torna\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\torna\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\torna\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\torna\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:713\u001b[0m, in \u001b[0;36mRandomHorizontalFlip.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;124;03m    img (PIL Image or Tensor): Image to be flipped.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;124;03m    PIL Image or Tensor: Randomly flipped image.\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp:\n\u001b[1;32m--> 713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mhflip(img)\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\torna\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py:659\u001b[0m, in \u001b[0;36mhflip\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m    657\u001b[0m     _log_api_usage_once(hflip)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mhflip(img)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mhflip(img)\n",
      "File \u001b[1;32mc:\\Users\\torna\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:54\u001b[0m, in \u001b[0;36mhflip\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhflip\u001b[39m(img: Image\u001b[38;5;241m.\u001b[39mImage) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_pil_image(img):\n\u001b[1;32m---> 54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be PIL Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(img)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mtranspose(Image\u001b[38;5;241m.\u001b[39mFLIP_LEFT_RIGHT)\n",
      "\u001b[1;31mTypeError\u001b[0m: img should be PIL Image. Got <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "options = {\n",
    "    (0, 0, 0),\n",
    "    (0, 0, 45),\n",
    "    (0, 1, 0),\n",
    "    (0, 1, 45),\n",
    "    (1, 0, 0),\n",
    "    (1, 0, 45),\n",
    "    (1, 1, 0),\n",
    "    (1, 1, 45)\n",
    "}\n",
    "\n",
    "tensor = np.arange(18).reshape(2, 3, 3)\n",
    "answer = []\n",
    "\n",
    "for idx, option in enumerate(options):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=option[0]),\n",
    "        transforms.RandomVerticalFlip(p=option[1]),\n",
    "        transforms.RandomRotation(degrees=option[2])\n",
    "    ])\n",
    "    answer[idx] = transform(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0  1  2]\n",
      "   [ 3  4  5]\n",
      "   [ 6  7  8]]\n",
      "\n",
      "  [[ 9 10 11]\n",
      "   [12 13 14]\n",
      "   [15 16 17]]]]\n",
      "[[[[ 6  7  8]\n",
      "   [ 3  4  5]\n",
      "   [ 0  1  2]]\n",
      "\n",
      "  [[15 16 17]\n",
      "   [12 13 14]\n",
      "   [ 9 10 11]]]]\n",
      "[[[[ 2  1  0]\n",
      "   [ 5  4  3]\n",
      "   [ 8  7  6]]\n",
      "\n",
      "  [[11 10  9]\n",
      "   [14 13 12]\n",
      "   [17 16 15]]]]\n"
     ]
    }
   ],
   "source": [
    "array = np.arange(18).reshape(1, 2, 3, 3)\n",
    "print(array)\n",
    "\n",
    "print(np.flip(array, axis=2))\n",
    "print(np.flip(array, axis=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.arange(18).reshape(1, 2, 3, 3)\n",
    "array2 = np.rot90(array, 1, (2, 3))\n",
    "\n",
    "aa = np.concatenate((array, array2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1],\n",
       "       [4, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [[1, 2], [3, 4]]\n",
    "np.flip(lst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1,  2],\n",
      "          [ 3,  4,  5],\n",
      "          [ 6,  7,  8]],\n",
      "\n",
      "         [[ 9, 10, 11],\n",
      "          [12, 13, 14],\n",
      "          [15, 16, 17]]]])\n",
      "tensor([[[[ 6,  7,  8],\n",
      "          [ 3,  4,  5],\n",
      "          [ 0,  1,  2]],\n",
      "\n",
      "         [[15, 16, 17],\n",
      "          [12, 13, 14],\n",
      "          [ 9, 10, 11]]]])\n",
      "tensor([[[[ 2,  1,  0],\n",
      "          [ 5,  4,  3],\n",
      "          [ 8,  7,  6]],\n",
      "\n",
      "         [[11, 10,  9],\n",
      "          [14, 13, 12],\n",
      "          [17, 16, 15]]]])\n",
      "tensor([[[[ 8,  7,  6],\n",
      "          [ 5,  4,  3],\n",
      "          [ 2,  1,  0]],\n",
      "\n",
      "         [[17, 16, 15],\n",
      "          [14, 13, 12],\n",
      "          [11, 10,  9]]]])\n"
     ]
    }
   ],
   "source": [
    "array = torch.arange(18).view(1, 2, 3, 3)\n",
    "print(array)\n",
    "\n",
    "print(torch.flip(array, dims=[2]))\n",
    "print(torch.flip(array, dims=[3]))\n",
    "print(torch.flip(array, dims=[2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[     18,      37,      56,  ...,     322,     341,     360],\n",
      "          [     17,      36,      55,  ...,     321,     340,     359],\n",
      "          [     16,      35,      54,  ...,     320,     339,     358],\n",
      "          ...,\n",
      "          [      2,      21,      40,  ...,     306,     325,     344],\n",
      "          [      1,      20,      39,  ...,     305,     324,     343],\n",
      "          [      0,      19,      38,  ...,     304,     323,     342]],\n",
      "\n",
      "         [[    379,     398,     417,  ...,     683,     702,     721],\n",
      "          [    378,     397,     416,  ...,     682,     701,     720],\n",
      "          [    377,     396,     415,  ...,     681,     700,     719],\n",
      "          ...,\n",
      "          [    363,     382,     401,  ...,     667,     686,     705],\n",
      "          [    362,     381,     400,  ...,     666,     685,     704],\n",
      "          [    361,     380,     399,  ...,     665,     684,     703]],\n",
      "\n",
      "         [[    740,     759,     778,  ...,    1044,    1063,    1082],\n",
      "          [    739,     758,     777,  ...,    1043,    1062,    1081],\n",
      "          [    738,     757,     776,  ...,    1042,    1061,    1080],\n",
      "          ...,\n",
      "          [    724,     743,     762,  ...,    1028,    1047,    1066],\n",
      "          [    723,     742,     761,  ...,    1027,    1046,    1065],\n",
      "          [    722,     741,     760,  ...,    1026,    1045,    1064]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  16263,   16282,   16301,  ...,   16567,   16586,   16605],\n",
      "          [  16262,   16281,   16300,  ...,   16566,   16585,   16604],\n",
      "          [  16261,   16280,   16299,  ...,   16565,   16584,   16603],\n",
      "          ...,\n",
      "          [  16247,   16266,   16285,  ...,   16551,   16570,   16589],\n",
      "          [  16246,   16265,   16284,  ...,   16550,   16569,   16588],\n",
      "          [  16245,   16264,   16283,  ...,   16549,   16568,   16587]],\n",
      "\n",
      "         [[  16624,   16643,   16662,  ...,   16928,   16947,   16966],\n",
      "          [  16623,   16642,   16661,  ...,   16927,   16946,   16965],\n",
      "          [  16622,   16641,   16660,  ...,   16926,   16945,   16964],\n",
      "          ...,\n",
      "          [  16608,   16627,   16646,  ...,   16912,   16931,   16950],\n",
      "          [  16607,   16626,   16645,  ...,   16911,   16930,   16949],\n",
      "          [  16606,   16625,   16644,  ...,   16910,   16929,   16948]],\n",
      "\n",
      "         [[  16985,   17004,   17023,  ...,   17289,   17308,   17327],\n",
      "          [  16984,   17003,   17022,  ...,   17288,   17307,   17326],\n",
      "          [  16983,   17002,   17021,  ...,   17287,   17306,   17325],\n",
      "          ...,\n",
      "          [  16969,   16988,   17007,  ...,   17273,   17292,   17311],\n",
      "          [  16968,   16987,   17006,  ...,   17272,   17291,   17310],\n",
      "          [  16967,   16986,   17005,  ...,   17271,   17290,   17309]]],\n",
      "\n",
      "\n",
      "        [[[  17346,   17365,   17384,  ...,   17650,   17669,   17688],\n",
      "          [  17345,   17364,   17383,  ...,   17649,   17668,   17687],\n",
      "          [  17344,   17363,   17382,  ...,   17648,   17667,   17686],\n",
      "          ...,\n",
      "          [  17330,   17349,   17368,  ...,   17634,   17653,   17672],\n",
      "          [  17329,   17348,   17367,  ...,   17633,   17652,   17671],\n",
      "          [  17328,   17347,   17366,  ...,   17632,   17651,   17670]],\n",
      "\n",
      "         [[  17707,   17726,   17745,  ...,   18011,   18030,   18049],\n",
      "          [  17706,   17725,   17744,  ...,   18010,   18029,   18048],\n",
      "          [  17705,   17724,   17743,  ...,   18009,   18028,   18047],\n",
      "          ...,\n",
      "          [  17691,   17710,   17729,  ...,   17995,   18014,   18033],\n",
      "          [  17690,   17709,   17728,  ...,   17994,   18013,   18032],\n",
      "          [  17689,   17708,   17727,  ...,   17993,   18012,   18031]],\n",
      "\n",
      "         [[  18068,   18087,   18106,  ...,   18372,   18391,   18410],\n",
      "          [  18067,   18086,   18105,  ...,   18371,   18390,   18409],\n",
      "          [  18066,   18085,   18104,  ...,   18370,   18389,   18408],\n",
      "          ...,\n",
      "          [  18052,   18071,   18090,  ...,   18356,   18375,   18394],\n",
      "          [  18051,   18070,   18089,  ...,   18355,   18374,   18393],\n",
      "          [  18050,   18069,   18088,  ...,   18354,   18373,   18392]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  33591,   33610,   33629,  ...,   33895,   33914,   33933],\n",
      "          [  33590,   33609,   33628,  ...,   33894,   33913,   33932],\n",
      "          [  33589,   33608,   33627,  ...,   33893,   33912,   33931],\n",
      "          ...,\n",
      "          [  33575,   33594,   33613,  ...,   33879,   33898,   33917],\n",
      "          [  33574,   33593,   33612,  ...,   33878,   33897,   33916],\n",
      "          [  33573,   33592,   33611,  ...,   33877,   33896,   33915]],\n",
      "\n",
      "         [[  33952,   33971,   33990,  ...,   34256,   34275,   34294],\n",
      "          [  33951,   33970,   33989,  ...,   34255,   34274,   34293],\n",
      "          [  33950,   33969,   33988,  ...,   34254,   34273,   34292],\n",
      "          ...,\n",
      "          [  33936,   33955,   33974,  ...,   34240,   34259,   34278],\n",
      "          [  33935,   33954,   33973,  ...,   34239,   34258,   34277],\n",
      "          [  33934,   33953,   33972,  ...,   34238,   34257,   34276]],\n",
      "\n",
      "         [[  34313,   34332,   34351,  ...,   34617,   34636,   34655],\n",
      "          [  34312,   34331,   34350,  ...,   34616,   34635,   34654],\n",
      "          [  34311,   34330,   34349,  ...,   34615,   34634,   34653],\n",
      "          ...,\n",
      "          [  34297,   34316,   34335,  ...,   34601,   34620,   34639],\n",
      "          [  34296,   34315,   34334,  ...,   34600,   34619,   34638],\n",
      "          [  34295,   34314,   34333,  ...,   34599,   34618,   34637]]],\n",
      "\n",
      "\n",
      "        [[[  34674,   34693,   34712,  ...,   34978,   34997,   35016],\n",
      "          [  34673,   34692,   34711,  ...,   34977,   34996,   35015],\n",
      "          [  34672,   34691,   34710,  ...,   34976,   34995,   35014],\n",
      "          ...,\n",
      "          [  34658,   34677,   34696,  ...,   34962,   34981,   35000],\n",
      "          [  34657,   34676,   34695,  ...,   34961,   34980,   34999],\n",
      "          [  34656,   34675,   34694,  ...,   34960,   34979,   34998]],\n",
      "\n",
      "         [[  35035,   35054,   35073,  ...,   35339,   35358,   35377],\n",
      "          [  35034,   35053,   35072,  ...,   35338,   35357,   35376],\n",
      "          [  35033,   35052,   35071,  ...,   35337,   35356,   35375],\n",
      "          ...,\n",
      "          [  35019,   35038,   35057,  ...,   35323,   35342,   35361],\n",
      "          [  35018,   35037,   35056,  ...,   35322,   35341,   35360],\n",
      "          [  35017,   35036,   35055,  ...,   35321,   35340,   35359]],\n",
      "\n",
      "         [[  35396,   35415,   35434,  ...,   35700,   35719,   35738],\n",
      "          [  35395,   35414,   35433,  ...,   35699,   35718,   35737],\n",
      "          [  35394,   35413,   35432,  ...,   35698,   35717,   35736],\n",
      "          ...,\n",
      "          [  35380,   35399,   35418,  ...,   35684,   35703,   35722],\n",
      "          [  35379,   35398,   35417,  ...,   35683,   35702,   35721],\n",
      "          [  35378,   35397,   35416,  ...,   35682,   35701,   35720]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[  50919,   50938,   50957,  ...,   51223,   51242,   51261],\n",
      "          [  50918,   50937,   50956,  ...,   51222,   51241,   51260],\n",
      "          [  50917,   50936,   50955,  ...,   51221,   51240,   51259],\n",
      "          ...,\n",
      "          [  50903,   50922,   50941,  ...,   51207,   51226,   51245],\n",
      "          [  50902,   50921,   50940,  ...,   51206,   51225,   51244],\n",
      "          [  50901,   50920,   50939,  ...,   51205,   51224,   51243]],\n",
      "\n",
      "         [[  51280,   51299,   51318,  ...,   51584,   51603,   51622],\n",
      "          [  51279,   51298,   51317,  ...,   51583,   51602,   51621],\n",
      "          [  51278,   51297,   51316,  ...,   51582,   51601,   51620],\n",
      "          ...,\n",
      "          [  51264,   51283,   51302,  ...,   51568,   51587,   51606],\n",
      "          [  51263,   51282,   51301,  ...,   51567,   51586,   51605],\n",
      "          [  51262,   51281,   51300,  ...,   51566,   51585,   51604]],\n",
      "\n",
      "         [[  51641,   51660,   51679,  ...,   51945,   51964,   51983],\n",
      "          [  51640,   51659,   51678,  ...,   51944,   51963,   51982],\n",
      "          [  51639,   51658,   51677,  ...,   51943,   51962,   51981],\n",
      "          ...,\n",
      "          [  51625,   51644,   51663,  ...,   51929,   51948,   51967],\n",
      "          [  51624,   51643,   51662,  ...,   51928,   51947,   51966],\n",
      "          [  51623,   51642,   51661,  ...,   51927,   51946,   51965]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[2166018, 2166037, 2166056,  ..., 2166322, 2166341, 2166360],\n",
      "          [2166017, 2166036, 2166055,  ..., 2166321, 2166340, 2166359],\n",
      "          [2166016, 2166035, 2166054,  ..., 2166320, 2166339, 2166358],\n",
      "          ...,\n",
      "          [2166002, 2166021, 2166040,  ..., 2166306, 2166325, 2166344],\n",
      "          [2166001, 2166020, 2166039,  ..., 2166305, 2166324, 2166343],\n",
      "          [2166000, 2166019, 2166038,  ..., 2166304, 2166323, 2166342]],\n",
      "\n",
      "         [[2166379, 2166398, 2166417,  ..., 2166683, 2166702, 2166721],\n",
      "          [2166378, 2166397, 2166416,  ..., 2166682, 2166701, 2166720],\n",
      "          [2166377, 2166396, 2166415,  ..., 2166681, 2166700, 2166719],\n",
      "          ...,\n",
      "          [2166363, 2166382, 2166401,  ..., 2166667, 2166686, 2166705],\n",
      "          [2166362, 2166381, 2166400,  ..., 2166666, 2166685, 2166704],\n",
      "          [2166361, 2166380, 2166399,  ..., 2166665, 2166684, 2166703]],\n",
      "\n",
      "         [[2166740, 2166759, 2166778,  ..., 2167044, 2167063, 2167082],\n",
      "          [2166739, 2166758, 2166777,  ..., 2167043, 2167062, 2167081],\n",
      "          [2166738, 2166757, 2166776,  ..., 2167042, 2167061, 2167080],\n",
      "          ...,\n",
      "          [2166724, 2166743, 2166762,  ..., 2167028, 2167047, 2167066],\n",
      "          [2166723, 2166742, 2166761,  ..., 2167027, 2167046, 2167065],\n",
      "          [2166722, 2166741, 2166760,  ..., 2167026, 2167045, 2167064]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2182263, 2182282, 2182301,  ..., 2182567, 2182586, 2182605],\n",
      "          [2182262, 2182281, 2182300,  ..., 2182566, 2182585, 2182604],\n",
      "          [2182261, 2182280, 2182299,  ..., 2182565, 2182584, 2182603],\n",
      "          ...,\n",
      "          [2182247, 2182266, 2182285,  ..., 2182551, 2182570, 2182589],\n",
      "          [2182246, 2182265, 2182284,  ..., 2182550, 2182569, 2182588],\n",
      "          [2182245, 2182264, 2182283,  ..., 2182549, 2182568, 2182587]],\n",
      "\n",
      "         [[2182624, 2182643, 2182662,  ..., 2182928, 2182947, 2182966],\n",
      "          [2182623, 2182642, 2182661,  ..., 2182927, 2182946, 2182965],\n",
      "          [2182622, 2182641, 2182660,  ..., 2182926, 2182945, 2182964],\n",
      "          ...,\n",
      "          [2182608, 2182627, 2182646,  ..., 2182912, 2182931, 2182950],\n",
      "          [2182607, 2182626, 2182645,  ..., 2182911, 2182930, 2182949],\n",
      "          [2182606, 2182625, 2182644,  ..., 2182910, 2182929, 2182948]],\n",
      "\n",
      "         [[2182985, 2183004, 2183023,  ..., 2183289, 2183308, 2183327],\n",
      "          [2182984, 2183003, 2183022,  ..., 2183288, 2183307, 2183326],\n",
      "          [2182983, 2183002, 2183021,  ..., 2183287, 2183306, 2183325],\n",
      "          ...,\n",
      "          [2182969, 2182988, 2183007,  ..., 2183273, 2183292, 2183311],\n",
      "          [2182968, 2182987, 2183006,  ..., 2183272, 2183291, 2183310],\n",
      "          [2182967, 2182986, 2183005,  ..., 2183271, 2183290, 2183309]]],\n",
      "\n",
      "\n",
      "        [[[2183346, 2183365, 2183384,  ..., 2183650, 2183669, 2183688],\n",
      "          [2183345, 2183364, 2183383,  ..., 2183649, 2183668, 2183687],\n",
      "          [2183344, 2183363, 2183382,  ..., 2183648, 2183667, 2183686],\n",
      "          ...,\n",
      "          [2183330, 2183349, 2183368,  ..., 2183634, 2183653, 2183672],\n",
      "          [2183329, 2183348, 2183367,  ..., 2183633, 2183652, 2183671],\n",
      "          [2183328, 2183347, 2183366,  ..., 2183632, 2183651, 2183670]],\n",
      "\n",
      "         [[2183707, 2183726, 2183745,  ..., 2184011, 2184030, 2184049],\n",
      "          [2183706, 2183725, 2183744,  ..., 2184010, 2184029, 2184048],\n",
      "          [2183705, 2183724, 2183743,  ..., 2184009, 2184028, 2184047],\n",
      "          ...,\n",
      "          [2183691, 2183710, 2183729,  ..., 2183995, 2184014, 2184033],\n",
      "          [2183690, 2183709, 2183728,  ..., 2183994, 2184013, 2184032],\n",
      "          [2183689, 2183708, 2183727,  ..., 2183993, 2184012, 2184031]],\n",
      "\n",
      "         [[2184068, 2184087, 2184106,  ..., 2184372, 2184391, 2184410],\n",
      "          [2184067, 2184086, 2184105,  ..., 2184371, 2184390, 2184409],\n",
      "          [2184066, 2184085, 2184104,  ..., 2184370, 2184389, 2184408],\n",
      "          ...,\n",
      "          [2184052, 2184071, 2184090,  ..., 2184356, 2184375, 2184394],\n",
      "          [2184051, 2184070, 2184089,  ..., 2184355, 2184374, 2184393],\n",
      "          [2184050, 2184069, 2184088,  ..., 2184354, 2184373, 2184392]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2199591, 2199610, 2199629,  ..., 2199895, 2199914, 2199933],\n",
      "          [2199590, 2199609, 2199628,  ..., 2199894, 2199913, 2199932],\n",
      "          [2199589, 2199608, 2199627,  ..., 2199893, 2199912, 2199931],\n",
      "          ...,\n",
      "          [2199575, 2199594, 2199613,  ..., 2199879, 2199898, 2199917],\n",
      "          [2199574, 2199593, 2199612,  ..., 2199878, 2199897, 2199916],\n",
      "          [2199573, 2199592, 2199611,  ..., 2199877, 2199896, 2199915]],\n",
      "\n",
      "         [[2199952, 2199971, 2199990,  ..., 2200256, 2200275, 2200294],\n",
      "          [2199951, 2199970, 2199989,  ..., 2200255, 2200274, 2200293],\n",
      "          [2199950, 2199969, 2199988,  ..., 2200254, 2200273, 2200292],\n",
      "          ...,\n",
      "          [2199936, 2199955, 2199974,  ..., 2200240, 2200259, 2200278],\n",
      "          [2199935, 2199954, 2199973,  ..., 2200239, 2200258, 2200277],\n",
      "          [2199934, 2199953, 2199972,  ..., 2200238, 2200257, 2200276]],\n",
      "\n",
      "         [[2200313, 2200332, 2200351,  ..., 2200617, 2200636, 2200655],\n",
      "          [2200312, 2200331, 2200350,  ..., 2200616, 2200635, 2200654],\n",
      "          [2200311, 2200330, 2200349,  ..., 2200615, 2200634, 2200653],\n",
      "          ...,\n",
      "          [2200297, 2200316, 2200335,  ..., 2200601, 2200620, 2200639],\n",
      "          [2200296, 2200315, 2200334,  ..., 2200600, 2200619, 2200638],\n",
      "          [2200295, 2200314, 2200333,  ..., 2200599, 2200618, 2200637]]],\n",
      "\n",
      "\n",
      "        [[[2200674, 2200693, 2200712,  ..., 2200978, 2200997, 2201016],\n",
      "          [2200673, 2200692, 2200711,  ..., 2200977, 2200996, 2201015],\n",
      "          [2200672, 2200691, 2200710,  ..., 2200976, 2200995, 2201014],\n",
      "          ...,\n",
      "          [2200658, 2200677, 2200696,  ..., 2200962, 2200981, 2201000],\n",
      "          [2200657, 2200676, 2200695,  ..., 2200961, 2200980, 2200999],\n",
      "          [2200656, 2200675, 2200694,  ..., 2200960, 2200979, 2200998]],\n",
      "\n",
      "         [[2201035, 2201054, 2201073,  ..., 2201339, 2201358, 2201377],\n",
      "          [2201034, 2201053, 2201072,  ..., 2201338, 2201357, 2201376],\n",
      "          [2201033, 2201052, 2201071,  ..., 2201337, 2201356, 2201375],\n",
      "          ...,\n",
      "          [2201019, 2201038, 2201057,  ..., 2201323, 2201342, 2201361],\n",
      "          [2201018, 2201037, 2201056,  ..., 2201322, 2201341, 2201360],\n",
      "          [2201017, 2201036, 2201055,  ..., 2201321, 2201340, 2201359]],\n",
      "\n",
      "         [[2201396, 2201415, 2201434,  ..., 2201700, 2201719, 2201738],\n",
      "          [2201395, 2201414, 2201433,  ..., 2201699, 2201718, 2201737],\n",
      "          [2201394, 2201413, 2201432,  ..., 2201698, 2201717, 2201736],\n",
      "          ...,\n",
      "          [2201380, 2201399, 2201418,  ..., 2201684, 2201703, 2201722],\n",
      "          [2201379, 2201398, 2201417,  ..., 2201683, 2201702, 2201721],\n",
      "          [2201378, 2201397, 2201416,  ..., 2201682, 2201701, 2201720]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[2216919, 2216938, 2216957,  ..., 2217223, 2217242, 2217261],\n",
      "          [2216918, 2216937, 2216956,  ..., 2217222, 2217241, 2217260],\n",
      "          [2216917, 2216936, 2216955,  ..., 2217221, 2217240, 2217259],\n",
      "          ...,\n",
      "          [2216903, 2216922, 2216941,  ..., 2217207, 2217226, 2217245],\n",
      "          [2216902, 2216921, 2216940,  ..., 2217206, 2217225, 2217244],\n",
      "          [2216901, 2216920, 2216939,  ..., 2217205, 2217224, 2217243]],\n",
      "\n",
      "         [[2217280, 2217299, 2217318,  ..., 2217584, 2217603, 2217622],\n",
      "          [2217279, 2217298, 2217317,  ..., 2217583, 2217602, 2217621],\n",
      "          [2217278, 2217297, 2217316,  ..., 2217582, 2217601, 2217620],\n",
      "          ...,\n",
      "          [2217264, 2217283, 2217302,  ..., 2217568, 2217587, 2217606],\n",
      "          [2217263, 2217282, 2217301,  ..., 2217567, 2217586, 2217605],\n",
      "          [2217262, 2217281, 2217300,  ..., 2217566, 2217585, 2217604]],\n",
      "\n",
      "         [[2217641, 2217660, 2217679,  ..., 2217945, 2217964, 2217983],\n",
      "          [2217640, 2217659, 2217678,  ..., 2217944, 2217963, 2217982],\n",
      "          [2217639, 2217658, 2217677,  ..., 2217943, 2217962, 2217981],\n",
      "          ...,\n",
      "          [2217625, 2217644, 2217663,  ..., 2217929, 2217948, 2217967],\n",
      "          [2217624, 2217643, 2217662,  ..., 2217928, 2217947, 2217966],\n",
      "          [2217623, 2217642, 2217661,  ..., 2217927, 2217946, 2217965]]]])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "# array = torch.arange(2217984).view(128, 48, 19, 19)\n",
    "array = torch.arange(18).view(1, 2, 3, 3)\n",
    "def trans_board(state):\n",
    "    if random.randint(0, 7) == 0:\n",
    "        return state\n",
    "    elif random.randint(0, 7) == 1:\n",
    "        return torch.rot90(state, k=1, dims=[2, 3])\n",
    "    elif random.randint(0, 7) == 2:\n",
    "        return torch.flip(state, dims=[2])\n",
    "    elif random.randint(0, 7) == 3:\n",
    "        return torch.rot90(torch.flip(state, dims=[2]), k=1, dims=[2, 3])\n",
    "    elif random.randint(0, 7) == 4:\n",
    "        return torch.flip(state, dims=[3])\n",
    "    elif random.randint(0, 7) == 5:\n",
    "        return torch.rot90(torch.flip(state, dims=[3]), k=1, dims=[2, 3])\n",
    "    elif random.randint(0, 7) == 6:\n",
    "        return torch.flip(torch.flip(state, dims=[3]), dims=[2])\n",
    "    elif random.randint(0, 7) == 7:\n",
    "        return torch.rot90(torch.flip(torch.flip(state, dims=[3]), dims=[2]), k=1, dims=[2, 3])\n",
    "\n",
    "array = trans_board(array)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 6,  3,  0],\n",
      "          [ 7,  4,  1],\n",
      "          [ 8,  5,  2]],\n",
      "\n",
      "         [[15, 12,  9],\n",
      "          [16, 13, 10],\n",
      "          [17, 14, 11]]]])\n"
     ]
    }
   ],
   "source": [
    "array = torch.arange(18).view(1, 2, 3, 3)\n",
    "def test(state):\n",
    "    return torch.rot90(torch.flip(torch.flip(state, dims=[3]), dims=[2]), k=1, dims=[2, 3])\n",
    "\n",
    "array = test(array)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss1:  2.9697\n",
      "Batch Loss2: 1.6418\n",
      "Actual class: tensor([16,  0,  1]),\n",
      " Y_pred1: tensor([13, 13, 13]), Y_pred2: tensor([0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "loss = nn.CrossEntropyLoss(weight=torch.tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=torch.float32)) # loss(input,target) 순서로 입력!\n",
    "\n",
    "# target is of size nBatch = 3\n",
    "# Y (=target) 은 class label 형태로 입력되어야 한다 (ex, 0,1,2 ...)\n",
    "Y = torch.tensor([16, 0, 1])\n",
    "\n",
    "# input is of size nBatch x nClasses = 3 x 3\n",
    "# Y_pred are logits, raw data 형태로 입력되어야 한다. \n",
    "Y_pred_good = torch.tensor(\n",
    "    [[0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2 , 0.3, 0.1, 0.2, 0.2, -100, 0.1, 0.1], # predict class 2\n",
    "    [0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2 , 0.3, 0.1, 0.2, 0.2, 0.1, 0.1, 0.1],  # predict class 0\n",
    "    [0.1, 0.2, 0.1, 0.2, 0.1, 0.2, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.2 , 0.3, 0.1, 0.2, 0.2, 0.1, 0.1, 0.1],]) # predict class 1\n",
    "\n",
    "Y_pred_bad = torch.tensor(\n",
    "    [[0.9, 0.2, 0.1],\n",
    "    [0.1, 0.3, 1.5],\n",
    "    [1.2, 0.2, 0.5]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "# l2 = loss(Y_pred_bad, Y)\n",
    "print(f'Batch Loss1:  {l1.item():.4f}')\n",
    "print(f'Batch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "# torch.max => input tensor의 elements중 최대 값을 반환한다.\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y},\\n Y_pred1: {predictions1}, Y_pred2: {predictions2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss1:  0.2834\n",
      "Batch Loss2: 1.6418\n",
      "Actual class: tensor([2, 0, 1]),\n",
      " Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "loss = nn.CrossEntropyLoss() # loss(input,target) 순서로 입력!\n",
    "\n",
    "# target is of size nBatch = 3\n",
    "# Y (=target) 은 class label 형태로 입력되어야 한다 (ex, 0,1,2 ...)\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "\n",
    "# input is of size nBatch x nClasses = 3 x 3\n",
    "# Y_pred are logits, raw data 형태로 입력되어야 한다. \n",
    "Y_pred_good = torch.tensor(\n",
    "    [[0.1, 0.2, 3.9], # predict class 2\n",
    "    [1.2, 0.1, 0.3],  # predict class 0\n",
    "    [0.3, 2.2, 0.2]]) # predict class 1\n",
    "\n",
    "Y_pred_bad = torch.tensor(\n",
    "    [[0.9, 0.2, 0.1],\n",
    "    [0.1, 0.3, 1.5],\n",
    "    [1.2, 0.2, 0.5]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "print(f'Batch Loss1:  {l1.item():.4f}')\n",
    "print(f'Batch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "# torch.max => input tensor의 elements중 최대 값을 반환한다.\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y},\\n Y_pred1: {predictions1}, Y_pred2: {predictions2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss1:  -0.2834\n",
      "Batch Loss2: 1.6418\n",
      "Actual class: tensor([2, 0, 1]),\n",
      " Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "def CELoss(output, action, advantage):\n",
    "    size = len(output)\n",
    "    result = torch.zeros(size)\n",
    "    for i in range(size):\n",
    "        value = (-1.0)*torch.log(torch.exp(output[i][action[i].long()]) / torch.sum(torch.exp(output[i])))*advantage[i]\n",
    "        result[i] = value\n",
    "    return torch.mean(result)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "loss = CELoss # loss(input,target) 순서로 입력!\n",
    "\n",
    "# target is of size nBatch = 3\n",
    "# Y (=target) 은 class label 형태로 입력되어야 한다 (ex, 0,1,2 ...)\n",
    "Y = torch.tensor([2, 0, 1])\n",
    "\n",
    "# input is of size nBatch x nClasses = 3 x 3\n",
    "# Y_pred are logits, raw data 형태로 입력되어야 한다. \n",
    "Y_pred_good = torch.tensor(\n",
    "    [[0.1, 0.2, 3.9], # predict class 2\n",
    "    [1.2, 0.1, 0.3],  # predict class 0\n",
    "    [0.3, 2.2, 0.2]]) # predict class 1\n",
    "\n",
    "Y_pred_bad = torch.tensor(\n",
    "    [[0.9, 0.2, 0.1],\n",
    "    [0.1, 0.3, 1.5],\n",
    "    [1.2, 0.2, 0.5]])\n",
    "\n",
    "l1 = loss(Y_pred_good, Y, [-1, -1, -1])\n",
    "l2 = loss(Y_pred_bad, Y, [1, 1, 1])\n",
    "print(f'Batch Loss1:  {l1.item():.4f}')\n",
    "print(f'Batch Loss2: {l2.item():.4f}')\n",
    "\n",
    "# get predictions\n",
    "# torch.max => input tensor의 elements중 최대 값을 반환한다.\n",
    "_, predictions1 = torch.max(Y_pred_good, 1)\n",
    "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
    "print(f'Actual class: {Y},\\n Y_pred1: {predictions1}, Y_pred2: {predictions2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\삼성\\AppData\\Local\\Temp\\ipykernel_12308\\2244725732.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nn.functional.softmax(torch.tensor([5, 3, 0], dtype=torch.float32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8756, 0.1185, 0.0059])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.softmax(torch.tensor([5, 3, 0], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201904"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('2019_04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 192, 19, 19]         230,400\n",
      "       BatchNorm2d-2          [-1, 192, 19, 19]             384\n",
      "              ReLU-3          [-1, 192, 19, 19]               0\n",
      "            Conv2d-4          [-1, 192, 19, 19]         331,776\n",
      "       BatchNorm2d-5          [-1, 192, 19, 19]             384\n",
      "              ReLU-6          [-1, 192, 19, 19]               0\n",
      "            Conv2d-7          [-1, 192, 19, 19]         331,776\n",
      "       BatchNorm2d-8          [-1, 192, 19, 19]             384\n",
      "            Conv2d-9          [-1, 192, 19, 19]         331,776\n",
      "      BatchNorm2d-10          [-1, 192, 19, 19]             384\n",
      "             ReLU-11          [-1, 192, 19, 19]               0\n",
      "           Conv2d-12          [-1, 192, 19, 19]         331,776\n",
      "      BatchNorm2d-13          [-1, 192, 19, 19]             384\n",
      "           Conv2d-14          [-1, 192, 19, 19]         331,776\n",
      "      BatchNorm2d-15          [-1, 192, 19, 19]             384\n",
      "             ReLU-16          [-1, 192, 19, 19]               0\n",
      "           Conv2d-17          [-1, 192, 19, 19]         331,776\n",
      "      BatchNorm2d-18          [-1, 192, 19, 19]             384\n",
      "           Conv2d-19          [-1, 192, 19, 19]         331,776\n",
      "      BatchNorm2d-20          [-1, 192, 19, 19]             384\n",
      "             ReLU-21          [-1, 192, 19, 19]               0\n",
      "           Conv2d-22          [-1, 192, 19, 19]         331,776\n",
      "      BatchNorm2d-23          [-1, 192, 19, 19]             384\n",
      "           Conv2d-24          [-1, 192, 19, 19]         331,776\n",
      "      BatchNorm2d-25          [-1, 192, 19, 19]             384\n",
      "             ReLU-26          [-1, 192, 19, 19]               0\n",
      "           Conv2d-27          [-1, 192, 19, 19]         331,776\n",
      "      BatchNorm2d-28          [-1, 192, 19, 19]             384\n",
      "           Conv2d-29            [-1, 1, 19, 19]             192\n",
      "================================================================\n",
      "Total params: 3,552,576\n",
      "Trainable params: 3,552,576\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 14.81\n",
      "Params size (MB): 13.55\n",
      "Estimated Total Size (MB): 28.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from dlgo.networks.alphago import AlphaGoPolicyResNet\n",
    "from torchsummary import summary\n",
    "\n",
    "model = AlphaGoPolicyResNet()\n",
    "\n",
    "summary(model.cuda(), (48, 19, 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def InverseCELoss(output, action):\n",
    "    batch_size = len(output)\n",
    "    feature_size = len(output[0])\n",
    "    result = torch.zeros(batch_size)\n",
    "    for i in range(batch_size):\n",
    "        value = 0\n",
    "        cum = torch.sum(torch.exp(output[i]))\n",
    "        for j in range(feature_size):\n",
    "            value += action[i][j] * torch.log(1 - torch.exp(output[i][j]) / cum)\n",
    "        result[i] = value\n",
    "    return (-1.0) * torch.mean(result)\n",
    "\n",
    "def CELoss(output, action):\n",
    "    batch_size = len(output)\n",
    "    feature_size = len(output[0])\n",
    "    result = torch.zeros(batch_size)\n",
    "    for i in range(batch_size):\n",
    "        value = 0\n",
    "        cum = torch.sum(torch.exp(output[i]))\n",
    "        for j in range(feature_size):\n",
    "            value += action[i][j] * torch.log(torch.exp(output[i][j]) / cum)\n",
    "        result[i] = value\n",
    "    return (-1.0) * torch.mean(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[2, 5, 1], [3, 2, 1], [0.5, 2, 0.1]])\n",
    "b = torch.tensor([[0.2, 0.5, 0.3], [0.3, 0.2, 0.5], [0.5, 0.2, 0.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7034)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CELoss(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7034)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "print(loss_fn(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4301)\n"
     ]
    }
   ],
   "source": [
    "c = torch.tensor([1, 2, 0])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "print(loss_fn(a, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4301)\n"
     ]
    }
   ],
   "source": [
    "f = torch.tensor([[0.0, -1.0, 0.0], [0.0, 0.0, -1.0], [-1.0, 0.0, 0.0]])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "print(loss_fn(a, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6376)\n"
     ]
    }
   ],
   "source": [
    "d = torch.tensor([[-0.2, -0.5, -0.3], [-0.3, -0.2, -0.5], [-0.5, -0.2, -0.3]])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "print(loss_fn(-a, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7356)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InverseCELoss(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\삼성\\AppData\\Local\\Temp\\ipykernel_5304\\59062038.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nn.functional.softmax(torch.tensor([2.0, 5.0, 1.0]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0466, 0.9362, 0.0171])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.softmax(torch.tensor([2.0, 5.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\삼성\\AppData\\Local\\Temp\\ipykernel_5304\\1765222308.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  nn.functional.softmax(torch.tensor([-2.0, -5.0, -1.0]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2654, 0.0132, 0.7214])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.softmax(torch.tensor([-2.0, -5.0, -1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0025) tensor(0.0158) tensor(0.0019)\n"
     ]
    }
   ],
   "source": [
    "cum1 = torch.sum(torch.exp(a[0]))\n",
    "cum2 = torch.sum(torch.exp(a[1]))\n",
    "cum3 = torch.sum(torch.exp(a[2]))\n",
    "value1 = b[0][0] * torch.log(torch.exp(a[0][0])) / cum1\n",
    "value2 = b[0][1] * torch.log(torch.exp(a[0][1])) / cum1\n",
    "value3 = b[0][2] * torch.log(torch.exp(a[0][2])) / cum1\n",
    "print(value1, value2, value3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 1],\n",
       "       [0, 0, 0],\n",
       "       [1, 2, 3],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[3, 2, 1], [0, 0, 0]])\n",
    "b = np.array([[1, 2, 3], [1, 1, 1]])\n",
    "\n",
    "c = np.concatenate([a, b])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
